{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Train off-the-shelf machine learning models with one line of code Documentation \u2022 Github \u2022 Contact traintool is a Python library for applied machine learning . It allows you to train off-the-shelf models with minimum code: You just give your data and say which model you want to train, and traintool takes care of the rest. It has pre-implemented models for most major use cases, works with different data formats and follows best practices for experiment tracking and deployment . Alpha Release Note that traintool is in an early alpha release. The API can and will change without notice. If you find a bug, please file an issue on Github or write me . Installation \u00b6 pip install git+https://github.com/jrieke/traintool Is traintool for you? \u00b6 YES if you... need to solve standard ML tasks with standard, off-the-shelf models prefer 98 % accuracy with one line of code over 98.1 % with 1000 lines want to compare different model types (e.g. deep network vs. SVM) care about experiment tracking & deployment NO if you... need to customize every aspect of your model, e.g. in basic research want to chase state of the art Features \u00b6 Minimum coding \u2014 traintool is designed from the ground up to require as few lines of code as possible. It offers a sleek and intuitive interface that gets you started in seconds. Training a model just takes a single line: traintool . train ( \"resnet18\" , train_data , test_data ) Pre-implemented models \u2014 traintool offers fully implemented and tested models \u2013 from simple classifiers to deep neural networks. The alpha version supports image classification only but we will add more models soon. Here are only a few of the models you can use: \"svm\" , \"random-forest\" , \"alexnet\" , \"resnet50\" , \"inception_v3\" , ... Easy, yet fully customizable \u2014 You can customize every aspect of the model training and hyperparameters. Simply pass along a config dictionary: traintool . train ( ... , config = { \"optimizer\" : \"adam\" , \"lr\" : 0.1 }) Automatic experiment tracking \u2014 traintool automatically calculates metrics and stores them \u2013 without requiring you to write any code. You can visualize the results with tensorboard or stream directly to comet.ml . Automatic saving and checkpoints \u2014 traintool automatically stores model checkpoints, logs, and experiment information in an intuitive directory structure. No more worrying about where you've put that one good experiment or which configuration it had. Works with multiple data formats \u2014 traintool understands numpy arrays, pytorch datasets, or files and automatically converts them to the correct format for the model you train. Instant deployment \u2014 You can deploy your model with one line of code to a REST API that you can query from anywhere. Just call: model . deploy () Built on popular ML libraries \u2014 Under the hood, traintool uses common open-source frameworks like pytorch, tensorflow, and scikit-learn. You can always access the raw models from these frameworks if you want to do more complex analysis: torch_model = model . raw ()[ \"model\" ] Example: Image classification on MNIST \u00b6 import mnist import traintool # Load MNIST data as numpy arrays (also works with torch/tensorflow datasets, files, ...) train_data = [ mnist . train_images (), mnist . train_labels ()] test_data = [ mnist . test_images (), mnist . test_labels ()] # Train SVM svm = traintool . train ( \"svm\" , train_data = train_data , test_data = test_data ) # Train ResNet with custom hyperparameters & track metrics to tensorboard config = { \"lr\" : 0.1 , \"optimizer\" : \"adam\" } resnet = traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data , config = config , tensorboard = True ) # Make prediction result = resnet . predict ( test_data [ 0 ][ 0 ]) print ( result [ \"predicted_class\" ]) # Deploy to REST API (with fastapi) resnet . deploy () # Get underlying pytorch model (e.g. for custom analysis) pytorch_model = resnet . raw ()[ \"model\" ] Interested? Have a look at the tutorial or check out available models . Get in touch! \u00b6 You have a question on traintool, want to use it in production, or miss a feature? I'm happy to hear from you! Write me at johannes.rieke@gmail.com .","title":"About"},{"location":"#installation","text":"pip install git+https://github.com/jrieke/traintool","title":"Installation"},{"location":"#is-traintool-for-you","text":"YES if you... need to solve standard ML tasks with standard, off-the-shelf models prefer 98 % accuracy with one line of code over 98.1 % with 1000 lines want to compare different model types (e.g. deep network vs. SVM) care about experiment tracking & deployment NO if you... need to customize every aspect of your model, e.g. in basic research want to chase state of the art","title":"Is traintool for you?"},{"location":"#features","text":"Minimum coding \u2014 traintool is designed from the ground up to require as few lines of code as possible. It offers a sleek and intuitive interface that gets you started in seconds. Training a model just takes a single line: traintool . train ( \"resnet18\" , train_data , test_data ) Pre-implemented models \u2014 traintool offers fully implemented and tested models \u2013 from simple classifiers to deep neural networks. The alpha version supports image classification only but we will add more models soon. Here are only a few of the models you can use: \"svm\" , \"random-forest\" , \"alexnet\" , \"resnet50\" , \"inception_v3\" , ... Easy, yet fully customizable \u2014 You can customize every aspect of the model training and hyperparameters. Simply pass along a config dictionary: traintool . train ( ... , config = { \"optimizer\" : \"adam\" , \"lr\" : 0.1 }) Automatic experiment tracking \u2014 traintool automatically calculates metrics and stores them \u2013 without requiring you to write any code. You can visualize the results with tensorboard or stream directly to comet.ml . Automatic saving and checkpoints \u2014 traintool automatically stores model checkpoints, logs, and experiment information in an intuitive directory structure. No more worrying about where you've put that one good experiment or which configuration it had. Works with multiple data formats \u2014 traintool understands numpy arrays, pytorch datasets, or files and automatically converts them to the correct format for the model you train. Instant deployment \u2014 You can deploy your model with one line of code to a REST API that you can query from anywhere. Just call: model . deploy () Built on popular ML libraries \u2014 Under the hood, traintool uses common open-source frameworks like pytorch, tensorflow, and scikit-learn. You can always access the raw models from these frameworks if you want to do more complex analysis: torch_model = model . raw ()[ \"model\" ]","title":"Features"},{"location":"#example-image-classification-on-mnist","text":"import mnist import traintool # Load MNIST data as numpy arrays (also works with torch/tensorflow datasets, files, ...) train_data = [ mnist . train_images (), mnist . train_labels ()] test_data = [ mnist . test_images (), mnist . test_labels ()] # Train SVM svm = traintool . train ( \"svm\" , train_data = train_data , test_data = test_data ) # Train ResNet with custom hyperparameters & track metrics to tensorboard config = { \"lr\" : 0.1 , \"optimizer\" : \"adam\" } resnet = traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data , config = config , tensorboard = True ) # Make prediction result = resnet . predict ( test_data [ 0 ][ 0 ]) print ( result [ \"predicted_class\" ]) # Deploy to REST API (with fastapi) resnet . deploy () # Get underlying pytorch model (e.g. for custom analysis) pytorch_model = resnet . raw ()[ \"model\" ] Interested? Have a look at the tutorial or check out available models .","title":"Example: Image classification on MNIST"},{"location":"#get-in-touch","text":"You have a question on traintool, want to use it in production, or miss a feature? I'm happy to hear from you! Write me at johannes.rieke@gmail.com .","title":"Get in touch!"},{"location":"models/image-classification/","text":"Image classification \u00b6 Models for image classification take in and image and output one label. Input formats \u00b6 Numpy arrays \u00b6 Each data split should be a list of two elements: The first element is a numpy array of all images of size (number of images, color channels, width, height) . The second element is an array of labels (integers). Example: train_images = np . zeros ( 32 , 3 , 256 , 256 ) # 32 images with 3 color channels and size 256x256 train_labels = np . zeros ( 32 ) train_data = [ train_images , train_labels ] Pytorch datasets \u00b6 Each element of the dataset should be a tuple: The first element is a torch tensor of the image of size (color channels, width, height) . The second element is the label as integer. All datasets from torchvision are compatible to this format. Files \u00b6 Coming soon! Preprocessing \u00b6 TODO Models \u00b6 TODO","title":"Image classification"},{"location":"models/image-classification/#image-classification","text":"Models for image classification take in and image and output one label.","title":"Image classification"},{"location":"models/image-classification/#input-formats","text":"","title":"Input formats"},{"location":"models/image-classification/#numpy-arrays","text":"Each data split should be a list of two elements: The first element is a numpy array of all images of size (number of images, color channels, width, height) . The second element is an array of labels (integers). Example: train_images = np . zeros ( 32 , 3 , 256 , 256 ) # 32 images with 3 color channels and size 256x256 train_labels = np . zeros ( 32 ) train_data = [ train_images , train_labels ]","title":"Numpy arrays"},{"location":"models/image-classification/#pytorch-datasets","text":"Each element of the dataset should be a tuple: The first element is a torch tensor of the image of size (color channels, width, height) . The second element is the label as integer. All datasets from torchvision are compatible to this format.","title":"Pytorch datasets"},{"location":"models/image-classification/#files","text":"Coming soon!","title":"Files"},{"location":"models/image-classification/#preprocessing","text":"TODO","title":"Preprocessing"},{"location":"models/image-classification/#models","text":"TODO","title":"Models"},{"location":"models/object-detection/","text":"Object detection \u00b6 Coming soon!","title":"Object detection"},{"location":"models/object-detection/#object-detection","text":"Coming soon!","title":"Object detection"},{"location":"models/text-classification/","text":"Text classification \u00b6 Coming soon!","title":"Text classification"},{"location":"models/text-classification/#text-classification","text":"Coming soon!","title":"Text classification"},{"location":"tutorial/deployment/","text":"Deployment \u00b6 traintool can automatically deploy your model through a REST API (using FastAPI under the hood). Simply run: model . deploy () This will start a server on 127.0.0.1 at port 8000 (modify via host and port arguments). The API offers a POST endpoint /predict which works similar to the predict method described above.","title":"Deployment"},{"location":"tutorial/deployment/#deployment","text":"traintool can automatically deploy your model through a REST API (using FastAPI under the hood). Simply run: model . deploy () This will start a server on 127.0.0.1 at port 8000 (modify via host and port arguments). The API offers a POST endpoint /predict which works similar to the predict method described above.","title":"Deployment"},{"location":"tutorial/experiment-tracking/","text":"Experiment tracking \u00b6 traintool tracks common metrics automatically (e.g. accuracy on train and test set) and has different options to store and visualize them. Tensorboard \u00b6 Tensorboard is a popular visualization toolkit from Google's tensorflow framework. By default, traintool automatically stores logs for tensorboard along with the model, so that you can visualize the metrics of your experiments. To start tensorboard, run on your terminal (from the project dir): tensorboard --logdir traintool-experiments Navigate your browser to http://localhost:6006/ and you should see the tensorboard window: INSERT IMAGE HERE On the bottom left, you can select all the different runs (same names as the directories in traintool-experiments ), on the right side you can view the metrics. If you want to disable tensorboard logging for a run, use traintool.train(..., tensorboard=False) . Comet.ml \u00b6 You can store these metrics in comet.ml , a popular platform for experiment tracking. They offer free accounts (you can sign up with your Github account), and free premium for students & academia. Once you have your account, log in to comet.ml, click on your profile in the upper right corner, go on settings and on \"Generate API Key\". Pass this API key along to the train function like this: traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data , comet_config = { \"api_key\" : YOUR_API_KEY , \"project_name\" : OPTIONAL_PROJECT_NAME }) Now you can head on over to comet.ml and follow the metrics in real time!","title":"Experiment tracking"},{"location":"tutorial/experiment-tracking/#experiment-tracking","text":"traintool tracks common metrics automatically (e.g. accuracy on train and test set) and has different options to store and visualize them.","title":"Experiment tracking"},{"location":"tutorial/experiment-tracking/#tensorboard","text":"Tensorboard is a popular visualization toolkit from Google's tensorflow framework. By default, traintool automatically stores logs for tensorboard along with the model, so that you can visualize the metrics of your experiments. To start tensorboard, run on your terminal (from the project dir): tensorboard --logdir traintool-experiments Navigate your browser to http://localhost:6006/ and you should see the tensorboard window: INSERT IMAGE HERE On the bottom left, you can select all the different runs (same names as the directories in traintool-experiments ), on the right side you can view the metrics. If you want to disable tensorboard logging for a run, use traintool.train(..., tensorboard=False) .","title":"Tensorboard"},{"location":"tutorial/experiment-tracking/#cometml","text":"You can store these metrics in comet.ml , a popular platform for experiment tracking. They offer free accounts (you can sign up with your Github account), and free premium for students & academia. Once you have your account, log in to comet.ml, click on your profile in the upper right corner, go on settings and on \"Generate API Key\". Pass this API key along to the train function like this: traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data , comet_config = { \"api_key\" : YOUR_API_KEY , \"project_name\" : OPTIONAL_PROJECT_NAME }) Now you can head on over to comet.ml and follow the metrics in real time!","title":"Comet.ml"},{"location":"tutorial/intro/","text":"Intro \u00b6 This tutorial shows you everything that traintool can do. We will train a few different models on MNIST, use automated experiment tracking, deploy the models via REST APIs, and get access to the underlying, raw models. Installation \u00b6 If you haven't installed traintool yet, now is a good time: pip install git+https://github.com/jrieke/traintool Dataset \u00b6 We will use the MNIST dataset throughout this tutorial. Just in case you never heard of it: MNIST is a popular dataset for image classification. It contains images of handwritten digits and the task is to predict which digit is shown on a given image. Below are some examples.","title":"Intro"},{"location":"tutorial/intro/#intro","text":"This tutorial shows you everything that traintool can do. We will train a few different models on MNIST, use automated experiment tracking, deploy the models via REST APIs, and get access to the underlying, raw models.","title":"Intro"},{"location":"tutorial/intro/#installation","text":"If you haven't installed traintool yet, now is a good time: pip install git+https://github.com/jrieke/traintool","title":"Installation"},{"location":"tutorial/intro/#dataset","text":"We will use the MNIST dataset throughout this tutorial. Just in case you never heard of it: MNIST is a popular dataset for image classification. It contains images of handwritten digits and the task is to predict which digit is shown on a given image. Below are some examples.","title":"Dataset"},{"location":"tutorial/raw-models/","text":"Getting access to raw models \u00b6 traintool gives you full access to the raw models it uses under the hood (e.g. from sklearn or pytorch). Just call: sklearn_model = model . raw ()[ \"model\" ] In some cases, the dictionary returned by model.raw() might also contain some other objects, e.g. data scalers.","title":"Getting access to raw models"},{"location":"tutorial/raw-models/#getting-access-to-raw-models","text":"traintool gives you full access to the raw models it uses under the hood (e.g. from sklearn or pytorch). Just call: sklearn_model = model . raw ()[ \"model\" ] In some cases, the dictionary returned by model.raw() might also contain some other objects, e.g. data scalers.","title":"Getting access to raw models"},{"location":"tutorial/training/","text":"Training and Prediction \u00b6 Your first model \u00b6 As a first example, we'll train a very simple model: A Support Vector Machine or SVM. We will use the image classification dataset MNIST throughout this tutorial, so let's load it now (the mnist package was installed along with traintool): import mnist train_data = [ mnist . train_images (), mnist . train_labels ()] test_data = [ mnist . test_images (), mnist . test_labels ()] Tip The code above loads the data as numpy arrays but traintool can also deal with files and pytorch datasets (see here). More data formats will be added soon. Training the SVM is very simple now: import traintool svm = traintool . train ( \"svm\" , train_data = train_data , test_data = test_data ) That's it! traintool will take care of reading and converting the data, applying some light preprocessing, training and saving the model, and tracking all metrics. It will also print out the final loss and accuracy (the test accuracy should be around XX % here). Making predictions \u00b6 Of course, you can do predictions with the trained model. Let's run it on an image of the test set: pred = svm . predict ( test_data [ 0 ][ 0 ]) print ( \"Predicted:\" , pred [ \"predicted_class\" ], \" - Is:\" , test_data [ 1 ][ 0 ]) This should print out the predicted class and the ground truth. Note that pred is a dictionary with the predicted class ( pred[\"predicted_class\"] ) and the probabilities for each class ( pred[\"probabilities\"] ). Tip Again, we use a numpy array for the test image here but traintool can also handle pytorch tensors and files. You can even pass in a whole batch of images (e.g. test_data[0][0:2] ). Using other models \u00b6 Now, let's check a more advanced model. We will train a Residual Network (ResNet), a modern deep neural network. Usually, training this model instead of an SVM would require you to use an advanced framework like pytorch or tensorflow and rewrite most of your codebase. With traintool, it's as simple replacing the model name in the train method: resnet = traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data ) And this syntax stays the same for every other model that traintool supports! This makes it really easy to compare a bunch of different models on your dataset and see what performs best. Custom hyperparameters \u00b6 In machine learning, most models have some hyperparameters that control the training process (e.g. the learning rate). traintool uses sensible defaults specific to each model, but gives you the flexibility to fully customize everything. First, let's find out which hyperparameters the model supports and what their defaults are: print ( traintool . default_hyperparameters ( \"resnet\" )) This should print out a dictionary of hyperparameters and defaults. Now, we want to change the learning rate and use a different optimizer. To do this, simply pass a config dict to the train method: config = { \"lr\" : 0.1 , \"optimizer\" : \"adam\" } better_resnet = traintool . train ( \"resnet\" , config = config , train_data = train_data , test_data = test_data ) Saving and loading models \u00b6 There are two options to save a model to disk. Either use the save method after training like this: model = traintool . train ( \"...\" ) model . save ( \"path/to/dir\" ) Or you can specify an output directory directly during training. This makes sense for long-running processes, so you don't lose the whole progress in case your machine is interrupted: model = traintool . train ( \"...\" , out_dir = \"path/to/dir\" ) In both cases, loading a model works via: model = traintool . load ( \"path/to/dir\" )","title":"Training and Prediction"},{"location":"tutorial/training/#training-and-prediction","text":"","title":"Training and Prediction"},{"location":"tutorial/training/#your-first-model","text":"As a first example, we'll train a very simple model: A Support Vector Machine or SVM. We will use the image classification dataset MNIST throughout this tutorial, so let's load it now (the mnist package was installed along with traintool): import mnist train_data = [ mnist . train_images (), mnist . train_labels ()] test_data = [ mnist . test_images (), mnist . test_labels ()] Tip The code above loads the data as numpy arrays but traintool can also deal with files and pytorch datasets (see here). More data formats will be added soon. Training the SVM is very simple now: import traintool svm = traintool . train ( \"svm\" , train_data = train_data , test_data = test_data ) That's it! traintool will take care of reading and converting the data, applying some light preprocessing, training and saving the model, and tracking all metrics. It will also print out the final loss and accuracy (the test accuracy should be around XX % here).","title":"Your first model"},{"location":"tutorial/training/#making-predictions","text":"Of course, you can do predictions with the trained model. Let's run it on an image of the test set: pred = svm . predict ( test_data [ 0 ][ 0 ]) print ( \"Predicted:\" , pred [ \"predicted_class\" ], \" - Is:\" , test_data [ 1 ][ 0 ]) This should print out the predicted class and the ground truth. Note that pred is a dictionary with the predicted class ( pred[\"predicted_class\"] ) and the probabilities for each class ( pred[\"probabilities\"] ). Tip Again, we use a numpy array for the test image here but traintool can also handle pytorch tensors and files. You can even pass in a whole batch of images (e.g. test_data[0][0:2] ).","title":"Making predictions"},{"location":"tutorial/training/#using-other-models","text":"Now, let's check a more advanced model. We will train a Residual Network (ResNet), a modern deep neural network. Usually, training this model instead of an SVM would require you to use an advanced framework like pytorch or tensorflow and rewrite most of your codebase. With traintool, it's as simple replacing the model name in the train method: resnet = traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data ) And this syntax stays the same for every other model that traintool supports! This makes it really easy to compare a bunch of different models on your dataset and see what performs best.","title":"Using other models"},{"location":"tutorial/training/#custom-hyperparameters","text":"In machine learning, most models have some hyperparameters that control the training process (e.g. the learning rate). traintool uses sensible defaults specific to each model, but gives you the flexibility to fully customize everything. First, let's find out which hyperparameters the model supports and what their defaults are: print ( traintool . default_hyperparameters ( \"resnet\" )) This should print out a dictionary of hyperparameters and defaults. Now, we want to change the learning rate and use a different optimizer. To do this, simply pass a config dict to the train method: config = { \"lr\" : 0.1 , \"optimizer\" : \"adam\" } better_resnet = traintool . train ( \"resnet\" , config = config , train_data = train_data , test_data = test_data )","title":"Custom hyperparameters"},{"location":"tutorial/training/#saving-and-loading-models","text":"There are two options to save a model to disk. Either use the save method after training like this: model = traintool . train ( \"...\" ) model . save ( \"path/to/dir\" ) Or you can specify an output directory directly during training. This makes sense for long-running processes, so you don't lose the whole progress in case your machine is interrupted: model = traintool . train ( \"...\" , out_dir = \"path/to/dir\" ) In both cases, loading a model works via: model = traintool . load ( \"path/to/dir\" ) <!-- --- This tutorial should show you everything to get started with traintool. We'll train and use a few different models on MNIST. ## Installation In the terminal, type: <div class=\"highlight\"> pip install git+https://github.com/jrieke/traintool Note that traintool requires Python 3. ## Data We will use the image classification dataset MNIST throughout this tutorial. It contains images of handwritten digits, that need to be classified according to the digit 0-9. To load it, start a Python console and enter: import mnist train_data = [ mnist . train_images (), mnist . train_labels ()] test_data = [ mnist . test_images (), mnist . test_labels ()] The `mnist` package should have been installed along with traintool. It loads the images and labels as numpy arrays. !!! tip Besides numpy arrays, traintool can also handle pytorch datasets and files. More data formats will be added soon. ## Training Train a [Support Vector Machine](https://en.wikipedia.org/wiki/Support_vector_machine): import traintool svm = traintool . train ( \"svm\" , train_data = train_data , test_data = test_data ) Or train a [Residual Network](https://arxiv.org/abs/1512.03385): resnet = traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data ) Or train any other model that traintool supports! It's as simple as changing the model name \u2013 no need to learn a new framework or change your entire code base. traintool makes it super easy to compare different models. ## Prediction Run an image from the test set through the model: pred = svm . predict ( test_data [ 0 ][ 0 ]) print ( \"Predicted:\" , pred [ \"predicted_class\" ], \" - Is:\" , test_data [ 1 ][ 0 ]) `pred` is a dictionary with the predicted class (`pred[\"predicted_class\"]`) and the probabilities for each class (`pred[\"probabilities\"]`) ## Hyperparameters Every model comes with sensible defaults for the hyperparameters. You can get these defaults via: print ( traintool . default_hyperparameters ( \"resnet\" )) To change hyperparameters, pass a `config` dict to the train method: config = { \"lr\" : 0.1 , \"optimizer\" : \"adam\" } better_resnet = traintool . train ( \"resnet\" , config = config , train_data = train_data , test_data = test_data ) >","title":"Saving and loading models"}]}